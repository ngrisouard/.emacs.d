{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of pix2pix101.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngrisouard/.emacs.d/blob/master/Copy_of_pix2pix101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BQxkmmVIWTRf"
      },
      "source": [
        "The following is a demo of pretty much everything. 2 main steps: preprocessing and training/testing\n",
        "\n",
        "# Image Preprocessing (Done Locally, ideally) \n",
        "\n",
        "To convert from Ponte's simulation .nc files to `combined/side-by-side` images (almost\\*) ready for training.\n",
        "\n",
        "\\*Need to remove blank images by hand\n",
        "\n",
        "\n",
        "\n",
        "## First part\n",
        "\n",
        "Use `tools/SnapPrints.py`. This allows you to specify custom colorbar, shape of image and txt file for absolute paths of simulations you want to use. \n",
        "\n",
        "To execute, run in terminal from `p2p-data-manipulation` folder (details about arguments in `SnapPrints.py`, **Check if true**):\n",
        "\n",
        "`python tools/SnapPrints.py --SimsToUse CustomSims.txt --ColourBar N3gauss --Shape Square`\n",
        "\n",
        "Note: This part should be done locally, since the the .txt file contains absolute paths from Data2. \n",
        "\n",
        "\n",
        "\n",
        "## Second part\n",
        "Use `tools/process.py` (for now, this needs to be run here using tensorflow, which is not on the workstation currently)\n",
        "\n",
        "`python tools/process.py --input_dir ssh --b_dir wave --operation combine --output_dir combined_snaps`\n",
        "\n",
        "Once tensorflow works locally, you can use `preprocess.sh` to do the above 2 in one step. This script also combines images , so we will run the script here. \n",
        "\n",
        "But before running anything here first we need to turn on the GPU and start a runtime:\n",
        "\n",
        "  * *Runtime -> Change runtime type -> Hardware Accelerator -> GPU*\n",
        "  * *Runtime -> Reset all runtimes*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8BpHRpJFpH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This cell defines different customized paths\n",
        "# You will need to modify it \n",
        "# gd_pth = '/Users/NicoG/GDrive/'  # path to the Google Drive folder on machine\n",
        "gd_pth = '/content/gdrive/'  # shoudl always be the same\n",
        "# Below: path to Google Drive folder containing code and images\n",
        "p2p_on_gd = os.path.join(gd_pth, 'GDrive/UofT/nico_pix2pix/')\n",
        "# p2p_on_gd = 'My\\ Drive/pix2pix/'  # Michael's original path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fZUiMoZQqvPy",
        "colab": {}
      },
      "source": [
        "# upload folder to google drive first.\n",
        "# You will need to change some paths if you change folder names\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount(gd_pth)\n",
        "preprocess = os.path.join(p2p_on_gd, 'tools/process.py')\n",
        "ssh = os.path.join(p2p_on_gd, 'ssh')\n",
        "wave = os.path.join(p2p_on_gd, 'wave')\n",
        "\n",
        "#make folder for combined images\n",
        "combined_snaps = os.path.join(p2p_on_gd, 'combined')\n",
        "if not os.path.isdir(combined_snaps):\n",
        "    os.mkdir(combined_snaps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TvpgCHCPqDJx",
        "colab": {}
      },
      "source": [
        "# This line below is to make sure the GPU is running. Usually the Nvidia Tesla\n",
        "# T4 is running (better), sometime you get the Nvidia K80 which is still not bad\n",
        "!nvidia-smi\n",
        "\n",
        "# This part below check how much of the GPU is being used. If Util is 0% (almost\n",
        "# always), you have the full GPUSometimes, Util = 95% (never happened to me\n",
        "# though, but others online). That means you only have 5% of the GPU.\n",
        "\n",
        "# You can ignore the details of this cell. Never changes, and is more of a check\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + \n",
        "       humanize.naturalsize( psutil.virtual_memory().available ), \n",
        "       \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(\n",
        "     gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ro9AFgi8qT0f"
      },
      "source": [
        "We also need to upload our folders to google drive and connect to it. If we keep files in the google colab 'cloud', it deletes after 12 hours, so we just use our drive as storage. This is pretty standard."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1BGGSZ_zW4dO",
        "colab": {}
      },
      "source": [
        "# Continuing to Second part\n",
        "!python $preprocess --input_dir $ssh --b_dir $wave --operation combine --output_dir $combined_snaps\n",
        " # Above: $ is to use a variable as an argument, I think"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Dnakj0o3jSnD"
      },
      "source": [
        "After images are combined, we manually remove blank images (from starts of simulations) and create a train/test set from the combined_snaps folder generated above. 80/20 split is recommended. \n",
        "\n",
        "I have not automated this part since it's quite short. Put all images into a train folder, then cut every 5th image into a test folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mp8ycl6Dh94F"
      },
      "source": [
        "# 2.  Training & Testing (Done on Scinet Graham/Google Colab, need GPU)\n",
        "\n",
        "For this demo, we will use Google Colab, but it should give you a good idea of how the training/testing/error metric process works. Running code here first can be helpful to see how long a simulation will take  (progress printed in real time) which can give you an idea of how much time required for Scinet. From my experience, they are about the same speed. \n",
        "\n",
        "For Scinet, I made an .sh file (pix2pix.sh) that has worked before on the Graham cluster. You can modify it to do multiple runs or whatnot.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Kdl2312eUkTX",
        "colab": {}
      },
      "source": [
        "pix2pix = os.path.join(p2p_on_gd, '/pix2pix/pix2pix.py')\n",
        "\n",
        "input_train = os.path.join(p2p_on_gd, 'train') # images to train on\n",
        "output_train = os.path.join(p2p_on_gd, 'trained') # folder to save trained model\n",
        "checkpoint = os.path.join(p2p_on_gd, 'trained')\n",
        "\n",
        "input_test = os.path.join(p2p_on_gd, 'test')\n",
        "output_test = os.path.join(p2p_on_gd, 'tested')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vXuikQPEiCeO",
        "colab": {}
      },
      "source": [
        "#if using rectangular images, add: --aspect_ratio=0.5\n",
        "#save_freq optional. Default is 5000, where #steps = #images*#epochs. \n",
        "#I put it there cause everytime a model is saved, the overwritten model (~500MB) goes to trash and can fill up Google Drive storage fast.\n",
        "\n",
        "!python $pix2pix --mode train --output_dir $output_train --max_epochs 500 --input_dir $input_train --which_direction AtoB --save_freq=20000 --aspect_ratio=0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bcZQ3PyEiWvT",
        "colab": {}
      },
      "source": [
        "#if using rectanglular images, add: --aspect_ratio=0.5\n",
        "!python $pix2pix --mode test --output_dir $output_test --input_dir $input_test --aspect_ratio=0.5 --checkpoint $checkpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gAGWZTor_uiV",
        "colab": {}
      },
      "source": [
        "# Finally we use L1 (pixel difference averaged along each RGB channel) as our error metric\n",
        "loss = os.path.join(p2p_on_gd, 'tools/loss.py')\n",
        "image_folder = os.path.join(p2p_on_gd, 'tested')\n",
        "!python $loss --image_dir $image_folder "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YVpioj6SBCZM",
        "colab": {}
      },
      "source": [
        "# load tensorboard for visualizing training (not testing)\n",
        "\n",
        "!pip install -q tf-nightly-2.0-preview\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S1wf47ceCzsZ",
        "colab": {}
      },
      "source": [
        "# if using tensorboard locally, you do not need the above cell, or the below '%' or '$'\n",
        "# we only care about generator_loss_L1\n",
        "%tensorboard --logdir $output_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "unxH7rK5idLZ"
      },
      "source": [
        "To run multiple tensorboards at once: https://stackoverflow.com/questions/36182380/how-do-display-different-runs-in-tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C-uoMOwnOdIh",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}